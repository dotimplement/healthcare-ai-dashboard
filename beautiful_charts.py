import marimo

__generated_with = "0.17.8"
app = marimo.App(width="columns")


@app.cell(column=0)
def _():
    import marimo as mo
    import pandas as pd
    from datetime import datetime, timedelta
    import numpy as np

    return datetime, mo, np, pd, timedelta


@app.cell(hide_code=True)
def _(datetime, np, pd, timedelta):
    def load_and_process_data():
        """Load and process the healthcare repository data"""
        df = pd.read_csv("healthcare_data.csv")

        # Remove unimportant categories
        df = df[
            ~df["Category"].isin(
                [
                    "Lists",
                    "Tutorials",
                    "Specification / Docs",
                    "Archived / Deprecated",
                    "Educational",
                ]
            )
        ]

        # Convert to datetime
        df["Created"] = pd.to_datetime(df["Created"])
        df["Last Commit"] = pd.to_datetime(df["Last Commit"])

        # Create new columns
        today = datetime.now()
        df["days_since_last_commit"] = (today - df["Last Commit"]).apply(
            lambda x: x.days
        )
        df["contributor_count"] = (
            df["Top Contributors"].fillna("").str.split(",").apply(len)
        )
        df["Org"] = df["Repository"].str.split("/").str[0]

        # Active definition: committed within last 365 days
        df["recent_activity_category"] = np.where(
            df["days_since_last_commit"] < 365, "Active", "Inactive"
        )

        # Additional processing for visualizations
        df["first_commit"] = df["Created"]
        df["last_commit"] = df["Last Commit"]
        df["lifespan_days"] = (df["last_commit"] - df["first_commit"]).dt.days
        df["start_year"] = df["first_commit"].dt.year
        df["is_active"] = df["last_commit"] >= (today - timedelta(days=365))

        # Process Standard column - handle multiple standards
        df["Standard"] = df["Standard"].fillna("None/Unknown")
        df["has_standard"] = df["Standard"] != "None/Unknown"

        # Create exploded dataframe for multi-standard analysis
        df["standards_list"] = df["Standard"].apply(
            lambda x: [s.strip() for s in str(x).split(",") if s.strip()]
        )

        # Load the classified repos CSV (generated by the GitHub classifier script)
        classified_df = pd.read_csv("repos_classified.csv")

        # Create a mapping dictionary from owner to organization status
        owner_classification = (
            classified_df.drop_duplicates(subset=["owner"])
            .set_index("owner")[["is_organization", "owner_type"]]
            .to_dict("index")
        )

        # Apply the classification to your main dataframe
        df["is_organization"] = df["Org"].map(
            lambda x: owner_classification.get(x, {}).get("is_organization", None)
        )
        df["owner_type"] = df["Org"].map(
            lambda x: owner_classification.get(x, {}).get("owner_type", "Unknown")
        )

        df["Created_years"] = "Upto 2016"

        df.loc[df["Created"].dt.year >= 2016, "Created_years"] = "2016-2018"
        df.loc[df["Created"].dt.year >= 2019, "Created_years"] = "2019-2021"
        df.loc[df["Created"].dt.year >= 2022, "Created_years"] = "2022-2025"

        mylist = [
            "epic",
            "Google",
            "apple",
            "hapi",
            "Firely",
            "microsoft",
            "awslabs",
            "google",
            "nextgen",
            "b2ihealth",
        ]
        pattern = "|".join(mylist)

        # Set 'owner type' to 'Research Lab' for matching repositories
        df.loc[
            df["Repository"].str.contains(pattern, case=False, na=False), "owner_type"
        ] = "Incumbent"

        mylist = [
            "tanford",
            "MIT",
            "complab",
            "sunlab",
            "ncbi",
            "islab",
            "ZhiGroup",
            "bowang",
            "NYU",
            "shahlab",
            "aiwong",
            "uf-hobi-informatics-lab",
            "MONAI",
            "Fudan",
            "healthylaife",
            "biosensing",
        ]
        pattern = "|".join(mylist)

        # Set 'owner type' to 'Research Lab' for matching repositories
        df.loc[
            df["Repository"].str.contains(pattern, case=False, na=False), "owner_type"
        ] = "Research Lab"

        mylist = [
            "synthetichealth",
            "medplum",
            "metriport",
            "bluehalo",
            "implement",
            "fastenhealth",
            "earthians",
            "fhirbase",
            "CogStack",
            "owkin",
            "beda-",
            "Vermonster",
            "masslight",
        ]
        pattern = "|".join(mylist)

        # Set 'owner type' to 'Research Lab' for matching repositories
        df.loc[
            df["Repository"].str.contains(pattern, case=False, na=False), "owner_type"
        ] = "Startup"

        mylist = [
            "openemr",
            "openmrs",
            "HospitalRun",
            "informatici",
            "OHDSI",
            "smart",
            "HL7",
            "Linux",
            "FHIR/",
            "cqframe",
            "analysisce",
            "LibreHealth",
            "oehf",
            "cds-hooks",
            "BiomedSci",
            "fhir-crucible",
            "samply",
            "mne-tools",
            "inferno-framework",
            "HealthIntersections",
        ]
        pattern = "|".join(mylist)

        # Set 'owner type' to 'Research Lab' for matching repositories
        df.loc[
            df["Repository"].str.contains(pattern, case=False, na=False), "owner_type"
        ] = "Community Project/Non-Profit"

        mylist = ["node-on-fhir", "ehrbase", "OpenHealthForAll"]
        pattern = "|".join(mylist)

        # Set 'owner type' to 'Research Lab' for matching repositories
        df.loc[
            df["Repository"].str.contains(pattern, case=False, na=False), "owner_type"
        ] = "User"

        return df

    return (load_and_process_data,)


@app.cell
def _(load_and_process_data):
    df_health = load_and_process_data()
    return (df_health,)


@app.cell
def _(df_health):
    df_interop = df_health[df_health["Category"] == "Interoperability"]
    return (df_interop,)


@app.cell
def _(pd):
    df_ownership = pd.read_csv("./repos_classified.csv")
    return (df_ownership,)


@app.cell
def _(df_ownership, interop_top_repo_stars):
    df_ownership[df_ownership["full_name"].isin(list(interop_top_repo_stars.index))]
    return


@app.cell
def _():
    ## Time series of languages over time
    return


@app.cell
def _():
    ## Time series of subcats over time
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    ## Breakdown of HAI Repos
    """
    )
    return


@app.cell
def _():
    # TODO: Either make this into a simple time series or keep bar chart
    return


@app.cell
def _():
    # df_health
    return


@app.cell
def _(df_ownership):
    df_ownership
    return


@app.cell
def _(df_ownership):
    df_ownership.value_counts("owner")
    return


@app.cell
def _(df_ownership):
    df_ownership
    return


@app.cell
def _():
    return


@app.cell
def _(df_ownership):
    df_ownership
    return


@app.cell
def _():
    return


@app.cell
def _(df_health):
    df_health["Created_years"].value_counts()
    return


@app.cell
def _(df_health):
    df_health.groupby(["Created_years", "owner_type"]).count()
    return


@app.cell
def _(df_health):
    df_health[
        (df_health["owner_type"] == "Organization")
        & (df_health["Created_years"] == "2022-2025")
    ]
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    - Todo
    - Eval Frameworks timeline. X axis: time yearly, y axis: number of evaluation framework repos created. Simple bar chart of line chart. Goal is to show uptick in eval tools post 2023.
    - Another graph should show subcat breakdown and uptick in evaluation frameworks since AI boom.
    - HAI engineering line chart (split into MCP vs non-mcp)
    - HAI engineering subcat breakdown
    - Whos building: ownership over time . Stacked chart with segments, big tech vs startups vs individual contributors. Want to hopefully show that big tech dominated the early years. This needs to properly process the data to account for not only creation date but end date. So at each point graph just shows active repos at that point in time.
    """
    )
    return


@app.cell(column=1)
def _(mo):
    mo.md(
        r"""
    ## Chart 1. Treemap
    """
    )
    return


@app.cell(hide_code=True)
def _(df_health):
    import plotly.express as px

    df = df_health.copy()
    df = df[~df["Category"].isin(["Archived", "Model repo"])]
    df = df.groupby(["Category", "Subcat"])["Stars"].count().reset_index()

    # Create custom text labels with counts
    df["label"] = df["Subcat"] + "<br>" + df["Stars"].astype(str)

    fig = px.treemap(
        df,
        path=["Category", "Subcat"],
        values="Stars",
        color_continuous_scale="RdBu",
        custom_data=["Stars"],
    )

    # Update text to show both label and count
    fig.update_traces(
        texttemplate="<b>%{label}</b><br>%{customdata[0]}",
        textposition="middle center",
        textfont=dict(size=14, color="white"),
        root_color="rgba(0,0,0,0)",
        marker=dict(line=dict(width=0)),
    )

    fig.show()
    fig.write_image("./nice_plots/treeplot.svg")
    return (px,)


@app.cell
def _(mo):
    mo.md(
        r"""
    ## Chart 2. Interoperability Repo Breakdown
    """
    )
    return


@app.cell(hide_code=True)
def _(df_interop, px):
    subcat_counts = df_interop["Subcat"].value_counts()

    # Calculate percentage for top 2 categories
    top_2_sum = subcat_counts.iloc[:2].sum()
    total = subcat_counts.sum()
    top_2_percentage = (top_2_sum / total) * 100

    fig_subcat = px.bar(
        x=subcat_counts.values,
        y=subcat_counts.index,
        orientation="h",
        title=f"Please Sir, may I have some Data?",
        subtitle="Breakdown of Interoperability Repos",
        labels={"x": "Number of Repositories", "y": "Subcategory"},
        # color=subcat_counts.values,
        # color_continuous_scale='Tealrose'
    )

    # Add values at the end of each bar
    fig_subcat.update_traces(
        text=subcat_counts.values, textposition="outside", textfont=dict(size=12)
    )

    fig_subcat.update_layout(height=500, yaxis={"categoryorder": "total ascending"})

    fig_subcat.update_layout(yaxis_title=None)
    fig_subcat.update_layout(legend=None)
    fig_subcat.update_layout()
    fig_subcat.show()
    fig_subcat.write_image("./nice_plots/interoperability.svg")
    return


@app.cell
def _(df_health, px):
    # Count the combinations
    counts = (
        df_health.groupby(["owner_type", "Category"]).size().reset_index(name="count")
    )

    # Create the grouped bar chart
    _fig = px.bar(
        counts,
        x="owner_type",
        y="count",
        color="Category",
        title="Count by Owner Type and Category",
        labels={"count": "Number of Rows", "owner_type": "Owner Type"},
        barmode="group",
    )  # This creates grouped bars side-by-side

    _fig.show()
    return


@app.cell(column=2)
def _(mo):
    mo.md(
        r"""
    ## Chart 3. Most popular Interoperability Repos
    """
    )
    return


@app.cell(hide_code=True)
def _(df_interop, px):
    # TODO: Add an additional legend for Personal/Organisation

    interop_top_repo_stars = (
        df_interop[["Repository", "Stars", "Subcat"]]
        .sort_values(by="Stars", ascending=False)
        .head(10)
        .set_index("Repository")
        .copy()
    )

    fig_interop_repos = px.bar(
        x=interop_top_repo_stars["Stars"],
        y=interop_top_repo_stars.index,
        orientation="h",
        title=f"Please Sir, may I have some Data?",
        subtitle="Most Popular Interoperability Repos",
        labels={"x": "Number of Repositories", "y": "Subcategory"},
        color=interop_top_repo_stars["Subcat"],
        color_continuous_scale="Teal",
    )

    # Add values at the end of each bar
    fig_interop_repos.update_traces(
        text=interop_top_repo_stars.values,
        textposition="outside",
        textfont=dict(size=12),
    )

    fig_interop_repos.update_layout(
        height=500, yaxis={"categoryorder": "total ascending"}
    )

    fig_interop_repos.update_layout(yaxis_title=None)
    fig_interop_repos.update_layout(legend=None)
    fig_interop_repos.update_layout()
    fig_interop_repos.show()
    fig_interop_repos.write_image("./nice_plots/interoperability_repos.svg")
    return (interop_top_repo_stars,)


@app.cell(hide_code=True)
def _(df_health, px):
    df_model_dev = df_health[df_health["Category"] == "Model Development"]

    _subcat_counts = df_model_dev["Subcat"].value_counts()

    _fig_subcat = px.bar(
        x=_subcat_counts.values,
        y=_subcat_counts.index,
        orientation="h",
        title=f"D'ya like models?",
        subtitle="Breakdown of Model Development Repos",
        labels={"x": "Number of Repositories", "y": "Subcategory"},
        # color=_subcat_counts.values,
        # color_continuous_scale='Teal'
    )

    # Add values at the end of each bar
    _fig_subcat.update_traces(
        text=_subcat_counts.values, textposition="outside", textfont=dict(size=12)
    )

    _fig_subcat.update_layout(height=500, yaxis={"categoryorder": "total ascending"})

    _fig_subcat.update_layout(yaxis_title=None)
    _fig_subcat.update_layout(legend=None)
    _fig_subcat.update_layout()
    _fig_subcat.show()
    _fig_subcat.write_image("./nice_plots/model_development.svg")
    return


@app.cell(hide_code=True)
def _(pd, timedelta):
    import plotly.graph_objects as go

    import requests

    from time import sleep
    from tqdm import tqdm

    # GitHub API Configuration
    # GITHUB_TOKEN = 'your_github_token_here'  # Replace with your token
    PLOT_TYPE = "stars"  # Options: 'count' or 'stars'

    def get_star_history(owner, repo, token):
        """
        Fetch complete star history for a GitHub repository.
        Returns a list of dicts with 'starred_at' timestamps.
        """
        stars = []
        page = 1

        headers = {
            "Accept": "application/vnd.github.v3.star+json",
            "Authorization": f"token {token}",
        }

        while True:
            url = f"https://api.github.com/repos/{owner}/{repo}/stargazers"
            params = {"per_page": 100, "page": page}

            response = requests.get(url, headers=headers, params=params)

            if response.status_code == 403:  # Rate limit
                print(f"Rate limit hit for {owner}/{repo}. Waiting...")
                sleep(60)
                continue
            elif response.status_code != 200:
                print(f"Error fetching {owner}/{repo}: {response.status_code}")
                break

            data = response.json()
            if not data:
                break

            stars.extend(data)
            page += 1

            # Small delay to avoid rate limiting
            sleep(0.1)

        return stars

    def process_star_history(df_health, token):
        """
        Process repositories and fetch their star histories.
        Returns a dataframe with time-series star events.
        """
        df_ts = df_health.copy()
        df_ts = df_ts[df_ts["owner_type"] != "Unknown"]
        df_ts = df_ts[
            df_ts["Category"].isin(
                [
                    "Interoperability",
                    "Infrastructure",
                    "Model Development",
                    "HAI Engineering",
                    "Archived",
                ]
            )
        ]
        df_ts = df_ts.sort_values(by="Stars", ascending=False).head(100)

        # Calculate the "active until" date
        df_ts["active_until"] = df_ts["Last Commit"] + timedelta(days=365)

        # Create events for star history
        star_events = []

        print("Fetching star histories from GitHub API...")
        for _, row in tqdm(df_ts.iterrows(), total=len(df_ts)):
            repo_full_name = row["Repository"]

            # Parse owner/repo from full name
            if "/" in repo_full_name:
                owner, repo = repo_full_name.split("/", 1)
            else:
                print(f"Skipping invalid repo name: {repo_full_name}")
                continue

            # Fetch star history from API
            star_history = get_star_history(owner, repo, token)

            if not star_history:
                print(f"No star history for {repo_full_name}")
                continue

            # Create events for each star
            for star in star_history:
                starred_at = pd.to_datetime(star["starred_at"])

                # Only count star if repo was active at that time
                if starred_at.tz_localize(None) >= row["Created"].tz_localize(None):
                    # Add star event
                    star_events.append(
                        {
                            "date": starred_at.tz_localize(None),
                            "change": 1,
                            "repo": repo_full_name,
                            "owner_type": row["owner_type"],
                            "event_type": "star_gained",
                        }
                    )

                    # Add corresponding "remove star" event when repo becomes inactive
                    # (if star was gained before repo became inactive)
                    if starred_at.tz_localize(None) < row["active_until"].tz_localize(
                        None
                    ):
                        star_events.append(
                            {
                                "date": row["active_until"].tz_localize(None),
                                "change": -1,
                                "repo": repo_full_name,
                                "owner_type": row["owner_type"],
                                "event_type": "star_removed_inactive",
                            }
                        )

        return pd.DataFrame(star_events)

    def plot_star_history(events_df):
        """
        Create an interactive Plotly chart of star history over time.
        """
        events_df = events_df[
            events_df["owner_type"].isin(
                ["Research Lab", "Community Project/Non-Profit", "Startup", "Incumbent"]
            )
        ]
        # Sort by date
        events_df = events_df.sort_values("date")

        # Get unique owner types
        owner_types = events_df["owner_type"].unique()

        # Create the plot
        fig = go.Figure()

        # Generate colors
        import plotly.express as px

        color_palette = px.colors.qualitative.Set2
        colors = {
            owner_type: color_palette[i % len(color_palette)]
            for i, owner_type in enumerate(sorted(owner_types))
        }

        for owner_type in owner_types:
            mask = events_df["owner_type"] == owner_type
            owner_events = events_df[mask].copy()
            owner_events["cumulative"] = owner_events["change"].cumsum()

            # Resample to monthly
            owner_events = (
                owner_events.set_index("date")["cumulative"]
                .resample("M")
                .last()
                .ffill()
                .reset_index()
            )
            owner_events = owner_events[owner_events["date"] < "2025-10-01"]

            color = colors[owner_type]

            fig.add_trace(
                go.Scatter(
                    x=owner_events["date"],
                    y=owner_events["cumulative"],
                    mode="lines",
                    name=owner_type.capitalize(),
                    line=dict(width=2, color=color),
                )
            )

        fig.update_layout(
            title="GitHub Stars in Active Repositories Over Time (Historical)",
            xaxis_title="Date",
            yaxis_title="Total Stars in Active Repositories",
            hovermode="x unified",
            template="plotly_white",
            height=500,
        )

        return fig

    def plot_star_history_bar(events_df):
        """
        Create an interactive Plotly bar chart of yearly star contributions by category.
        """
        events_df = events_df[
            events_df["owner_type"].isin(
                ["Research Lab", "Community Project/Non-Profit", "Startup", "Incumbent"]
            )
        ]
        events_df = events_df[events_df["change"] > 0]
        # Sort by date
        events_df = events_df.sort_values("date")

        # Extract year
        events_df["year"] = events_df["date"].dt.year

        # Filter out 2025 (partial year)
        events_df = events_df[events_df["year"] < 2026]

        # Get unique owner types
        owner_types = events_df["owner_type"].unique()

        # Generate colors
        import plotly.express as px

        color_palette = px.colors.qualitative.Set2
        colors = {
            owner_type: color_palette[i % len(color_palette)]
            for i, owner_type in enumerate(sorted(owner_types))
        }

        # Create the plot
        fig = go.Figure()

        # Group by year and owner_type, sum the changes
        yearly_data = (
            events_df.groupby(["year", "owner_type"])["change"].sum().reset_index()
        )

        for owner_type in sorted(owner_types):
            owner_data = yearly_data[yearly_data["owner_type"] == owner_type]
            color = colors[owner_type]

            fig.add_trace(
                go.Bar(
                    x=owner_data["year"],
                    y=owner_data["change"],
                    name=owner_type.capitalize(),
                    marker_color=color,
                )
            )

        fig.update_layout(
            title="Yearly GitHub Star Contributions by Category",
            xaxis_title="Year",
            yaxis_title="Stars Added",
            hovermode="x unified",
            template="plotly_white",
            height=500,
            barmode="stack",  # Stacked bars to show contribution to total
            xaxis=dict(type="category"),  # Treat years as categories for better spacing
        )

        return fig

    def plot_star_history_unstack_bar(events_df):
        """
        Create an interactive Plotly bar chart of yearly star contributions by category (as percentages).
        """
        events_df = events_df[
            events_df["owner_type"].isin(
                ["Research Lab", "Community Project/Non-Profit", "Startup", "Incumbent"]
            )
        ]
        events_df = events_df[events_df["change"] > 0]
        # Sort by date
        events_df = events_df.sort_values("date")

        # Extract year
        events_df["year"] = events_df["date"].dt.year

        # Filter out years before 2020 and after 2025
        events_df = events_df[(events_df["year"] >= 2020) & (events_df["year"] < 2026)]

        # Create year groups
        def group_years(year):
            # if year in [2017, 2018, 2019]:
            #     return '2017-19'
            if year in [2020, 2021, 2022]:
                return "2020-22"
            elif year in [2023, 2024, 2025]:
                return "2023-25"
            return str(year)

        events_df["year_group"] = events_df["year"].apply(group_years)

        # Get unique owner types
        owner_types = events_df["owner_type"].unique()

        # Generate colors
        import plotly.express as px

        color_palette = px.colors.qualitative.Set2
        colors = {
            owner_type: color_palette[i % len(color_palette)]
            for i, owner_type in enumerate(sorted(owner_types))
        }

        # Create the plot
        fig = go.Figure()

        # Group by year_group and owner_type, sum the changes
        yearly_data = (
            events_df.groupby(["year_group", "owner_type"])["change"]
            .sum()
            .reset_index()
        )

        # Calculate yearly totals
        yearly_totals = yearly_data.groupby("year_group")["change"].sum().reset_index()
        yearly_totals.columns = ["year_group", "total"]

        # Merge totals back and calculate percentages
        yearly_data = yearly_data.merge(yearly_totals, on="year_group")
        yearly_data["percentage"] = (yearly_data["change"] / yearly_data["total"]) * 100

        # Define order for x-axis
        year_order = ["2020/21", "2022/23", "2024/25"]

        for owner_type in sorted(owner_types):
            owner_data = yearly_data[yearly_data["owner_type"] == owner_type]
            color = colors[owner_type]

            fig.add_trace(
                go.Bar(
                    x=owner_data["year_group"],
                    y=owner_data["percentage"],
                    name=owner_type.capitalize(),
                    marker_color=color,
                )
            )

        fig.update_layout(
            title="GitHub Star Contributions by Category (Percentage)",
            xaxis_title="Year Period",
            yaxis_title="Percentage of Period Stars (%)",
            hovermode="x unified",
            template="plotly_white",
            height=500,
            barmode="group",  # Grouped bars side-by-side
            xaxis=dict(
                type="category",
                categoryorder="array",
                categoryarray=year_order,  # Ensure correct order
            ),
        )

        return fig

    def plot_star_history_line_gradient(events_df):
        """
        Create an interactive Plotly line chart showing the gradient of category contributions
        between two time periods.
        """
        events_df = events_df[
            events_df["owner_type"].isin(
                ["Research Lab", "Community Project/Non-Profit", "Startup", "Incumbent"]
            )
        ]
        events_df = events_df[events_df["change"] > 0]
        # Sort by date
        events_df = events_df.sort_values("date")

        # Extract year
        events_df["year"] = events_df["date"].dt.year

        # Filter out years before 2020 and after 2025
        events_df = events_df[(events_df["year"] >= 2020) & (events_df["year"] < 2026)]

        # Create year groups
        def group_years(year):
            if year in [2020, 2021, 2022]:
                return "2020-22"
            elif year in [2023, 2024, 2025]:
                return "2023-25"
            return str(year)

        events_df["year_group"] = events_df["year"].apply(group_years)

        # Get unique owner types
        owner_types = events_df["owner_type"].unique()

        # Generate colors
        import plotly.express as px

        color_palette = px.colors.qualitative.Set2
        colors = {
            owner_type: color_palette[i % len(color_palette)]
            for i, owner_type in enumerate(sorted(owner_types))
        }

        # Create the plot
        fig = go.Figure()

        # Group by year_group and owner_type, sum the changes
        yearly_data = (
            events_df.groupby(["year_group", "owner_type"])["change"]
            .sum()
            .reset_index()
        )

        # Calculate yearly totals
        yearly_totals = yearly_data.groupby("year_group")["change"].sum().reset_index()
        yearly_totals.columns = ["year_group", "total"]

        # Merge totals back and calculate percentages
        yearly_data = yearly_data.merge(yearly_totals, on="year_group")
        yearly_data["percentage"] = (yearly_data["change"] / yearly_data["total"]) * 100

        # Define order for x-axis
        year_order = ["2020-22", "2023-25"]

        for owner_type in sorted(owner_types):
            owner_data = yearly_data[yearly_data["owner_type"] == owner_type]
            color = colors[owner_type]

            # Sort to ensure correct order
            owner_data = owner_data.sort_values("year_group")

            fig.add_trace(
                go.Scatter(
                    x=owner_data["year_group"],
                    y=owner_data["percentage"],
                    name=owner_type.capitalize(),
                    mode="lines+markers",
                    line=dict(width=4, color=color),
                    marker=dict(size=12, color=color),
                )
            )

            fig.update_layout(
                title="GitHub Star Contributions by Category",
                xaxis_title="Year Period",
                yaxis_title="Percentage of Period Stars (%)",
                hovermode="x unified",
                template="plotly_white",
                height=500,
                font=dict(size=16),  # Global font size
                title_font=dict(size=20),  # Title font size
                xaxis=dict(
                    type="category",
                    categoryorder="array",
                    categoryarray=year_order,
                    range=[-0.3, 1.3],
                    title_font=dict(size=18),  # X-axis title font size
                    tickfont=dict(size=16),  # X-axis tick labels font size
                ),
                yaxis=dict(
                    title_font=dict(size=18),  # Y-axis title font size
                    tickfont=dict(size=16),  # Y-axis tick labels font size
                ),
                legend=dict(font=dict(size=16)),  # Legend font size
            )

        return fig

    return (
        go,
        plot_star_history,
        plot_star_history_bar,
        plot_star_history_line_gradient,
        plot_star_history_unstack_bar,
    )


@app.cell
def _(events_df):
    events_df["owner_type"].unique()
    return


@app.cell
def _(pd):
    # events_df.to_csv('star_events_history.csv')
    # Save the events for future use (to avoid re-fetching)
    events_df = pd.read_csv("star_events_history.csv")
    events_df.set_index("date", inplace=True)
    events_df.index = pd.to_datetime(events_df.index)
    events_df.reset_index(inplace=True)
    events_df.loc[
        events_df["repo"] == "OpenHealthForAll/open-health", "owner_type"
    ] = "User"
    # events_df = events_df[events_df['date']>'2018-01-01']
    return (events_df,)


@app.cell
def _(events_df, plot_star_history):
    # Fetch star history from GitHub API
    # Create and show the plot
    _fig = plot_star_history(events_df)
    _fig.show()
    return


@app.cell
def _():
    return


@app.cell
def _(events_df, plot_star_history):
    _fig = plot_star_history(events_df[events_df["change"] > 0])
    _fig.show()
    return


@app.cell
def _(events_df, plot_star_history_bar):
    _fig = plot_star_history_bar(events_df)
    _fig.show()
    return


@app.cell
def _(events_df, plot_star_history_unstack_bar):
    _fig = plot_star_history_unstack_bar(events_df)
    _fig.write_image("./nice_plots/star_by_category_bar.svg")
    _fig.show()
    return


@app.cell
def _(events_df, plot_star_history_line_gradient):
    _fig = plot_star_history_line_gradient(events_df)
    _fig.write_image("./nice_plots/star_by_category_line.svg")
    _fig.show()
    return


@app.cell
def _(df_health, go, pd, timedelta):
    df_health["active_until"] = df_health["Last Commit"] + timedelta(days=365)

    # Create events for each repository
    _events = []

    for _, _row in df_health.iterrows():
        # Repo becomes active (created)
        _events.append(
            {
                "date": _row["Created"],
                "change": 1,
                "repo": _row["Repository"],
                "owner_type": _row["owner_type"],
            }
        )

        # Repo becomes inactive (1 year after last commit)
        _events.append(
            {
                "date": _row["active_until"],
                "change": -1,
                "repo": _row["Repository"],
                "owner_type": _row["owner_type"],
            }
        )

    # Convert to dataframe and sort by date
    _events_df = pd.DataFrame(_events).sort_values("date")

    # Calculate cumulative active repos at each event
    _events_df["active_repos"] = _events_df["change"].cumsum()

    # Create the plot
    _fig = go.Figure()

    owner_types = _events_df["owner_type"].unique()

    for owner_type in owner_types:
        mask = _events_df["owner_type"] == owner_type
        owner_events = _events_df[mask].copy()
        owner_events["cumulative"] = owner_events["change"].cumsum()

        _fig.add_trace(
            go.Scatter(
                x=owner_events["date"],
                y=owner_events["cumulative"],
                mode="lines",
                name=owner_type.capitalize(),
                line=dict(width=2),
                # stackgroup='one',  # This creates a stacked area chart
            )
        )

    _fig.update_layout(
        title="GitHub Repository Activity Over Time",
        xaxis_title="Date",
        yaxis_title="Number of Active Repositories",
        hovermode="x unified",
        template="plotly_white",
        height=500,
    )

    _fig.show()
    return


@app.cell
def _():
    return


@app.cell(column=3)
def _():
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## FHIR Dominating
    """
    )
    return


@app.cell
def _():
    return


if __name__ == "__main__":
    app.run()
